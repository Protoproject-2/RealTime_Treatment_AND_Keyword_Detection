# サーバーサイドの問題点と解決策のまとめ

## 概要

現在、クライアントから送信された音声をサーバー側で処理する際に、以下の問題が発生しています。

##【最重要問題】同じ音声が繰り返し認識される

### 現象
- サーバーに複数回リクエストを送っても、サーバー側のログでは「ご視聴ありがとうございました」のような同じテキストが繰り返し認識される。
- これにより、クライアント側で実際に録音された音声が正しく処理されていない。

### 原因
- `KeywordDetector`クラスが利用している`whisper`ライブラリの`transcribe`メソッドのデフォルト動作が原因である可能性が極めて高いです。
- `transcribe`メソッドは、以前の認識結果を「文脈（コンテキスト）」として利用し、次の認識精度を上げようとします。
- この機能により、無音に近い音声データを受け取った場合などに、直前の有効だった認識結果を再び出力してしまっていると推測されます。

### 解決策
- `transcribe`メソッドを呼び出す際に、文脈の引き継ぎを無効にするオプションを追加します。

```python
# KeywordDetectorクラスのdetectメソッド内

# 【変更前】
result = self.model.transcribe(audio_data, language="ja")

# 【変更後】
result = self.model.transcribe(audio_data, language="ja", condition_on_previous_text=False)
```

この修正により、`whisper`は毎回、渡された音声データだけを元にゼロから文字起こしを行うようになり、問題の解決が期待できます。

---

##【参考】キーワード照合ロジックについて

### 現状
- 認識されたひらがなテキスト（例: `ごしちょうありがとうございました`）に、キーワード（例: `あ`）が**部分的にでも含まれていれば**、合致したと判定されます。
- ユーザーからは「この仕様で期待通り」と伺っていますが、意図しない検出（例: 「ありがとう」で「あ」が検出される）に繋がる可能性があります。

### 将来的な改善案
- もし、より厳密な判定が必要になった場合は、単純な`in`でのチェックから、形態素解析ライブラリ（Janomeなど）で単語単位に区切ってから照合する方法への変更が考えられます。
